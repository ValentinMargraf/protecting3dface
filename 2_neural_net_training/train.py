import numpy as np
from models import *
from utils import *
import argparse
import tensorflow as tf

ROOT = '../1_data_preprocessing/DATA_npy/'


def main():


    '''
    commented this out, since BDR data is not open source,
    therefore only TEXAS data (which can be generated by executing the jupyter notebook OR the python scrips
    inside 1_data_preprocessing!) to show functionality.

    # LOAD DATA
    # X: preprocessed, cropped faces
    # y: corresponding labels
    X1 = np.load(ROOT+'BDR_AUGMENTED_faces.npy')
    X2 = np.load(ROOT+'TEXAS_AUGMENTED_faces.npy')
    y1 = np.load(ROOT+'BDR_AUGMENTED_labels.npy')
    y2 = np.load(ROOT+'TEXAS_AUGMENTED_labels.npy')


    # maybe only take parts of the dataset, depending on your GPU
    X=np.concatenate((X1,X1))[:2000]
    y=np.concatenate((y1,y2))[:2000]
    '''


    # maybe only take parts of the dataset, depending on your GPU
    X = np.load(ROOT+'TEXAS_AUGMENTED_faces.npy')[:2000]
    y = np.load(ROOT+'TEXAS_AUGMENTED_labels.npy')[:2000]

    used_labels = set(list(y))
    print("num persons: ", len(list(used_labels)))

    MODEL = resnet('29_persons_relu.h5')

    # set params
    EPOCHS = 100
    # if you choose batchsize = 2 that means 2 images per person i.e. a batch of 2*29=58 images (look into utils.py batch_generator function for further details)
    BATCH_SIZE = 2
    # margin is not fix! try with different values, controls the distance between clusters of embeddings of different persons
    MARGIN = 1

    print("num persons: ", len(list(used_labels)))
    #set learning rates
    LR_1 = 0.00001
    LR_2 =  tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001,decay_steps=100,decay_rate=0.96,staircase=True)
    PATH_TO_SAVE = '29_persons_relu_NEWLY_TRAINED.h5'

    # be careful with this function, since it differs slightly between the resnet and the vgg in case you want to try the vgg
    MODEL.train_model(X, y, used_labels, EPOCHS, BATCH_SIZE, MARGIN, LR_1, LR_2,  PATH_TO_SAVE)


if __name__== "__main__" :
    main()
